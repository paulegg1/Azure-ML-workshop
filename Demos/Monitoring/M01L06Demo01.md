# Monitoring Data

## Introduction 

This demo shows how to monitor data.

**Note:** You can execute the demo locally on jupyter notebook by searching for jupyter in the search bar and click on jupyter notebook and this will launch the browser. There is a folder called '**MachineLearningInaDay**' that has all the .ipynb notebooks and data. 

Alternatively, you can also upload the notebook in the Azure Machine Learning workspace along with the data files and run the notebook from there. In both cases, you will reference the same machine learning workspace. The notebooks are located in '**C:\Workshop_Files**' as a copy in the demo machine

## Objectives 

In this demo we will:
-	Use a notebook and its associated dataset to create a MLflow machine learning model
-   Provision a Managed Online Endpoint 
-   Create a real time deployment
-   Enable Application Insights
-	Use resources in AML to monitor this model


## Estimated Time 

30 minutes 

## Scenario

While this entire demo will take approximately 30 minutes in total, some of this time will be spent waiting for Azure Machine Learning to complete certain processes. As a result, be prepared to discuss other options around monitoring models and Azure Machine Learning during these times. Corresponding ideas and talking points will be found below.

---

### Tasks


1.	Upload the **Monitoring Models.ipynb** notebook and its associated datasets to Azure Machine Learning.

2.	Execute each cell, walking through what each does, step by step.
    
    a.	Much of the content will be review for participants, as they have becoming accustomed to the steps from earlier in the workshop.

3.	Briefly explore the underlying dataset being used here. It is an open-source diabetes dataset, whose features are various metrics gathered as part of a series of blood tests, to predict the likelihood of a patient being diabetic.

4.	Point out how MLflow auto-generates the scoring script versus what they might have written ourselves beforehand.

5.	In the Deploy a Model section, be ready to discuss the differences between Azure Monitor and Application Insights while the model is being deployed.
    
    a.	What used to be known as Application Insights and Log Analytics independent offerings - are now a part of Azure Monitor.
    
    b.	Log Analytics is a feature inside of Azure Monitor.

6.	After having been deployed, we now want to consume the resource, so that logs will be generated.
    
    a.	Emphasize here that because we can view the metrics that were generated to output logs associated with the consumption of our model.


7.  Now, we can navigate back to the Azure Portal (portal.azure.com), and look at the corresponding results in Application Insights.

    <img src="Media/endpoint-deployment-metrics.png">

8.  Or be sure to look for the Applications Insight instance that was created along side the Azure Machine Learning Workspace as an alternative.

    <img src="Media/azure-app-insight.png">

9.  To view the Transactions, click on the **Investigate** category for more details.

    <img src="Media/azure-app-insight-transaction.png">

10. Try selecting one of the results for more details.

    <img src="Media/azure-app-insight-transaction-results.png">

11. View the logs by selecting the desired operation within the **Performance** tab.

    <img src="Media/azure-app-insight-performance.png">

12. Check out the query results from Azure Log Analytics

    <img src="Media/logs-kql-commands.png">

13.	Navigate to the relevant endpoint, and show off some of the different pieces of information contained here as well:
    
    a.	Deployment state, data related to resources associated with this endpoint, among others.
    
    b.	Note that these can also be called using python code as well.

### Congratulations!

You have successfully completed this exercise and the demo. You can move to the next demo.